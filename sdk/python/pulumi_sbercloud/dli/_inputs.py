# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins as _builtins
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities

__all__ = [
    'QueueScalingPolicyArgs',
    'QueueScalingPolicyArgsDict',
    'QueueSparkDriverArgs',
    'QueueSparkDriverArgsDict',
    'SparkJobDependentPackageArgs',
    'SparkJobDependentPackageArgsDict',
    'SparkJobDependentPackagePackageArgs',
    'SparkJobDependentPackagePackageArgsDict',
]

MYPY = False

if not MYPY:
    class QueueScalingPolicyArgsDict(TypedDict):
        impact_start_time: pulumi.Input[_builtins.str]
        impact_stop_time: pulumi.Input[_builtins.str]
        max_cu: pulumi.Input[_builtins.int]
        min_cu: pulumi.Input[_builtins.int]
        priority: pulumi.Input[_builtins.int]
elif False:
    QueueScalingPolicyArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class QueueScalingPolicyArgs:
    def __init__(__self__, *,
                 impact_start_time: pulumi.Input[_builtins.str],
                 impact_stop_time: pulumi.Input[_builtins.str],
                 max_cu: pulumi.Input[_builtins.int],
                 min_cu: pulumi.Input[_builtins.int],
                 priority: pulumi.Input[_builtins.int]):
        pulumi.set(__self__, "impact_start_time", impact_start_time)
        pulumi.set(__self__, "impact_stop_time", impact_stop_time)
        pulumi.set(__self__, "max_cu", max_cu)
        pulumi.set(__self__, "min_cu", min_cu)
        pulumi.set(__self__, "priority", priority)

    @_builtins.property
    @pulumi.getter(name="impactStartTime")
    def impact_start_time(self) -> pulumi.Input[_builtins.str]:
        return pulumi.get(self, "impact_start_time")

    @impact_start_time.setter
    def impact_start_time(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "impact_start_time", value)

    @_builtins.property
    @pulumi.getter(name="impactStopTime")
    def impact_stop_time(self) -> pulumi.Input[_builtins.str]:
        return pulumi.get(self, "impact_stop_time")

    @impact_stop_time.setter
    def impact_stop_time(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "impact_stop_time", value)

    @_builtins.property
    @pulumi.getter(name="maxCu")
    def max_cu(self) -> pulumi.Input[_builtins.int]:
        return pulumi.get(self, "max_cu")

    @max_cu.setter
    def max_cu(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "max_cu", value)

    @_builtins.property
    @pulumi.getter(name="minCu")
    def min_cu(self) -> pulumi.Input[_builtins.int]:
        return pulumi.get(self, "min_cu")

    @min_cu.setter
    def min_cu(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "min_cu", value)

    @_builtins.property
    @pulumi.getter
    def priority(self) -> pulumi.Input[_builtins.int]:
        return pulumi.get(self, "priority")

    @priority.setter
    def priority(self, value: pulumi.Input[_builtins.int]):
        pulumi.set(self, "priority", value)


if not MYPY:
    class QueueSparkDriverArgsDict(TypedDict):
        max_concurrent: NotRequired[pulumi.Input[_builtins.int]]
        max_instance: NotRequired[pulumi.Input[_builtins.int]]
        max_prefetch_instance: NotRequired[pulumi.Input[_builtins.str]]
elif False:
    QueueSparkDriverArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class QueueSparkDriverArgs:
    def __init__(__self__, *,
                 max_concurrent: Optional[pulumi.Input[_builtins.int]] = None,
                 max_instance: Optional[pulumi.Input[_builtins.int]] = None,
                 max_prefetch_instance: Optional[pulumi.Input[_builtins.str]] = None):
        if max_concurrent is not None:
            pulumi.set(__self__, "max_concurrent", max_concurrent)
        if max_instance is not None:
            pulumi.set(__self__, "max_instance", max_instance)
        if max_prefetch_instance is not None:
            pulumi.set(__self__, "max_prefetch_instance", max_prefetch_instance)

    @_builtins.property
    @pulumi.getter(name="maxConcurrent")
    def max_concurrent(self) -> Optional[pulumi.Input[_builtins.int]]:
        return pulumi.get(self, "max_concurrent")

    @max_concurrent.setter
    def max_concurrent(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "max_concurrent", value)

    @_builtins.property
    @pulumi.getter(name="maxInstance")
    def max_instance(self) -> Optional[pulumi.Input[_builtins.int]]:
        return pulumi.get(self, "max_instance")

    @max_instance.setter
    def max_instance(self, value: Optional[pulumi.Input[_builtins.int]]):
        pulumi.set(self, "max_instance", value)

    @_builtins.property
    @pulumi.getter(name="maxPrefetchInstance")
    def max_prefetch_instance(self) -> Optional[pulumi.Input[_builtins.str]]:
        return pulumi.get(self, "max_prefetch_instance")

    @max_prefetch_instance.setter
    def max_prefetch_instance(self, value: Optional[pulumi.Input[_builtins.str]]):
        pulumi.set(self, "max_prefetch_instance", value)


if not MYPY:
    class SparkJobDependentPackageArgsDict(TypedDict):
        group_name: pulumi.Input[_builtins.str]
        """
        Specifies the user group name.
        Changing this parameter will submit a new spark job.
        """
        packages: pulumi.Input[Sequence[pulumi.Input['SparkJobDependentPackagePackageArgsDict']]]
        """
        Specifies the user group resource for details.
        Changing this parameter will submit a new spark job.
        The object structure is documented below.

        <a name="dependent_packages_packages"></a>
        The `packages` block supports:
        """
elif False:
    SparkJobDependentPackageArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class SparkJobDependentPackageArgs:
    def __init__(__self__, *,
                 group_name: pulumi.Input[_builtins.str],
                 packages: pulumi.Input[Sequence[pulumi.Input['SparkJobDependentPackagePackageArgs']]]):
        """
        :param pulumi.Input[_builtins.str] group_name: Specifies the user group name.
               Changing this parameter will submit a new spark job.
        :param pulumi.Input[Sequence[pulumi.Input['SparkJobDependentPackagePackageArgs']]] packages: Specifies the user group resource for details.
               Changing this parameter will submit a new spark job.
               The object structure is documented below.
               
               <a name="dependent_packages_packages"></a>
               The `packages` block supports:
        """
        pulumi.set(__self__, "group_name", group_name)
        pulumi.set(__self__, "packages", packages)

    @_builtins.property
    @pulumi.getter(name="groupName")
    def group_name(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the user group name.
        Changing this parameter will submit a new spark job.
        """
        return pulumi.get(self, "group_name")

    @group_name.setter
    def group_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "group_name", value)

    @_builtins.property
    @pulumi.getter
    def packages(self) -> pulumi.Input[Sequence[pulumi.Input['SparkJobDependentPackagePackageArgs']]]:
        """
        Specifies the user group resource for details.
        Changing this parameter will submit a new spark job.
        The object structure is documented below.

        <a name="dependent_packages_packages"></a>
        The `packages` block supports:
        """
        return pulumi.get(self, "packages")

    @packages.setter
    def packages(self, value: pulumi.Input[Sequence[pulumi.Input['SparkJobDependentPackagePackageArgs']]]):
        pulumi.set(self, "packages", value)


if not MYPY:
    class SparkJobDependentPackagePackageArgsDict(TypedDict):
        package_name: pulumi.Input[_builtins.str]
        """
        Specifies the resource name of the package.
        Changing this parameter will submit a new spark job.
        """
        type: pulumi.Input[_builtins.str]
        """
        Specifies the resource type of the package.
        Changing this parameter will submit a new spark job.
        """
elif False:
    SparkJobDependentPackagePackageArgsDict: TypeAlias = Mapping[str, Any]

@pulumi.input_type
class SparkJobDependentPackagePackageArgs:
    def __init__(__self__, *,
                 package_name: pulumi.Input[_builtins.str],
                 type: pulumi.Input[_builtins.str]):
        """
        :param pulumi.Input[_builtins.str] package_name: Specifies the resource name of the package.
               Changing this parameter will submit a new spark job.
        :param pulumi.Input[_builtins.str] type: Specifies the resource type of the package.
               Changing this parameter will submit a new spark job.
        """
        pulumi.set(__self__, "package_name", package_name)
        pulumi.set(__self__, "type", type)

    @_builtins.property
    @pulumi.getter(name="packageName")
    def package_name(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the resource name of the package.
        Changing this parameter will submit a new spark job.
        """
        return pulumi.get(self, "package_name")

    @package_name.setter
    def package_name(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "package_name", value)

    @_builtins.property
    @pulumi.getter
    def type(self) -> pulumi.Input[_builtins.str]:
        """
        Specifies the resource type of the package.
        Changing this parameter will submit a new spark job.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input[_builtins.str]):
        pulumi.set(self, "type", value)


